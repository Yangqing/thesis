\chapter{Towards Better Image Features}

A key component in the object recognition pipeline is to extract robust yet representative features from perceptual inputs, usually in the format of raw pixels. Such features should be able to further support high-level interpretations such as categorization and detection, and the vision community has converged to specific architectures for feature extraction in the recent decade. Most notably, such architectures use a convolutional approach that encodes local image patches and spatially pools the output, and then stacks such convolutional components in a multi-layer fashion to build mid and high level features. Despite various ways on how such networks should be constructed (e.g.\ with handcrafted features or fully trained), such structures have remained effective in various applications, including digit recognition \cite{lecun1998gradient}, object detection \cite{Dalal:2005to}, object classification \cite{Yang:2009vb}, and the recent success of convolutional neural networks in large-scale classification tasks \cite{krizhevsky2012imagenet}.

This chapter focuses on the building block of such approaches - a single-layer network that contain one local coding stage and one spatial pooling stage. Specifically, we proposes a novel approach to perform pooling to obtain more selective features for object recognition, achieving higher performance on benchmark datasets than conventional pooling approaches do. We then explain the theoretical justification of a common phenomenon found in the single-layer network analysis: higher dimensional features almost always lead to better classification performance. This chapter focuses on the single-layer network for clarity, but the results we found would apply to multi-layer networks as well.

\section{Background}

Overcompletely encoded features have been shown to provide state-of-the-art performance on various applications. In computer vision, locally encoded and spatially pooled feature extraction pipelines work particularly well for image classification. Such pipelines usually start from densely extracted local image patches (either normalized raw pixel values or hand-crafted descriptors such as SIFT or HOG), and perform dictionary learning to obtain a dictionary of codes (also called filters). The patches are then encoded into an over-complete representation using various algorithms such as sparse coding \cite{Olshausen:1997uh,wang2010locality} or simple inner product with a non-linear post-processing \cite{coates2011icml,krizhevsky2012imagenet}. After encoding, spatial pooling with average or max operations are carried out to form a global image representation \cite{Yang:2009vb,Boureau:uq}. The encoding and pooling pipeline may be stacked in a deep structure to produce a final feature vector, which is then used to predict the labels for the images usually via a linear classifier or a densely connected multilayer neural network.

During the last decade, much emphasis has been directed at the coding step. Dictionary learning algorithms have been discussed to find a set of basis that reconstructs local image patches or descriptors well \cite{mairal2010online,coates2011icml}, and several encoding methods have been proposed to map the original data to a high-dimensional space that emphasizes certain properties, such as sparsity \cite{Olshausen:1997uh,Yang:2009vb,yang2010efficient} or locality \cite{wang2010locality}. Recent papers \cite{coates2010aistats, Rigamonti:2011uc, coates2011icml} have explored the relationship between dictionary learning and encoding, and have proposed simple yet effective approaches that achieve competitive results. The neuroscience justification of coding comes from simple neurons in the human visual cortex V1, which have been believed to produce sparse and overcomplete activations \cite{Olshausen:1997uh}.

Similarly, the idea of spatial pooling dates back to Hubel's seminal paper about complex cells in the mammalian visual cortex \cite{Hubel:1962vm}, which identifies mid-level image features that are invariant to small spatial shifting. The spatial invariance property also reflects the concept of locally orderless images \cite{Koenderink:1999bh}, which suggests that low-level features are grouped spatially to provide information about the overall semantics. Most recent research on spatial pooling aims to find a good pooling operator, which could be seen as a function that produces informative statistics based on local features in a specific spatial area. For example, average and max pooling strategies have been found in various algorithms respectively, and systematic comparisons between such pooling strategies have been presented and discussed in \cite{Boureau:uq,Boureau:2010wz}. Recently, Coates et al.\ proposed to pool over multiple features in the context of deep learning \cite{coates2011selecting}.

However, relatively little effort has been put into better designs or learning of better spatial regions for pooling, although it has been discussed in the context of learning local descriptors \cite{winder2007learning}. A predominant approach to define the spatial regions for pooling, which we will also call the receptive fields (borrowing the terminology from neuroscience) for the pooled features, comes from the idea of spatial pyramids \cite{lazebnik2006beyond, Yang:2009vb}, where regular grids of increasing granularity are used to pool local features. The spatial pyramids provide a reasonable cover over the image space with scale information, and most existing classification methods either use them directly, or use slightly modified/simplified versions.

In addition, recent research has revealed a particularly interesting finding \cite{coates2010aistats, Rigamonti:2011uc, coates2011icml, saxe2011random} that very simple patch-based algorithms like K-means or even random selection, combined with feed-forward encoding methods with a naive nonlinearity, produces state-of-the-art performance on various datasets. Explanation of such phenomenon often focuses on the local image patch statistics, such as the frequency selectivity of random samples \cite{saxe2011random}, but does not offer an asymptotic theory on the dictionary learning behavior. We will show later in the chapter that a \nystrom sampling based interpretation explains such phenomenon well by providing asymptotic bounds to the observed accuracy, and that such interpretation will lead to an efficient, unsupervised feature selection paradigm.

\section{The Classification Pipeline}\label{sec:pipeline}

\begin{figure*}[t]
  \centering
  \includegraphics[width=1.\textwidth]{figs/smartpooling/pipeline_cvpr.pdf}
  \caption{The image classification pipeline. See Section \ref{sec:pipeline} for details.}\label{fig:pipeline}
  \vspace{-0.15in}
\end{figure*}

Before the introduction of the proposed methods, we briefly review the image classification pipeline we adopted, which leads to the problem of learning the receptive fields for spatial pooling. Specifically, we will focus on two-layer classification approaches.

We illustrate the pipeline from raw images to the prediction of class labels in Figure \ref{fig:pipeline}. Specifically, starting with an input image $\bI$, two stages are usually adopted to generate the global feature, as we formally define below.

\paragraph{(1) Coding.} In the coding step, we extract local image patches, and encode each patch to $K$ activation values based on a codebook of size $K$ (learned via a separate dictionary learning step). These activations are typically binary (in the case of vector quantization) or continuous (in the case of e.g.\ sparse coding). It is generally believed that having an overcomplete ($K \gg$ the dimension of patches) codebook while keeping the activations sparse helps classification, especially when linear classifiers are used in the later steps.

Recently, Coates et al.~\cite{coates2011icml} have shown that relatively simple dictionary learning and encoding approaches lead to surprisingly good performances. To learn a dictionary $\bD =[\bd_1,\bd_2,\cdots,\bd_K]$ of size $K$ from randomly sampled patches $\{\bp_1,\bp_2,\cdots,\bp_N\}$ each reshaped as a vector of pixel values, two simple yet effective approaches are advocated:
\begin{enumerate}
  \item K-means, which minimizes the squared distance between each patch and its nearest code: $\min_{\bD} \sum_{i=1}^{N}\min_{j}\|\bp_i - \bd_j\|_2^2$.
  \item OMP-M, which learns a dictionary that minimizes the reconstruction error, with the constraint that each patch is modeled by a linear combination of at most $M$ codes: $\min_{\bD,\balpha_{i}} \sum_{i=1}^{N}\|\bp_i-\bD\balpha_i\|^{2}_{2}$, where the length of each dictionary entry $\bd_j$ is $1$, and the cardinality of each reconstruction coefficient $\balpha_i$ is at most $M$.
\end{enumerate}
For encoding, Coates et al.\ also propose to substitute sparse coding by the following efficient approaches:
\begin{enumerate}
  \item Triangle coding \cite{coates2010aistats}, which computes the activation of code $k$ for a patch $\bp$ as $f_k(\bx) = \max\{0,\mu(\bz) - z_k\}$, where $z_k$ is the distance from $\bp$ to the $k$-th code $\bd_k$, and $\mu(\bz)$ is the mean of distances from $\bp$ to all codes. 
  \item Soft thresholding, which computes the inner product between $\bp$ and each code, with a fixed threshold parameter $\alpha$: $f_{k}(\bx) = \max\{0, \bd_k^\top\bp - \alpha\}$
\end{enumerate}

We refer to \cite{coates2011icml} for a systematic discussion about different dictionary learning and encoding algorithms. In our experiment, we will adopt these standard approaches in order to isolate  the contribution of spatial pooling from the choice of different coding methods. Since local patches are usually extracted densely in a grid-based fashion, we will organize the activations of image $\bI$ as a set of matrices denoted by $\{\bA^{1}(\bI)\bA^{2}(\bI),\cdots,\bA^{K}(\bI)\}$, one for each code in the codebook, whose element $A_{ij}^k(\bI)$ contains the activation of code $\bd_k$ for the local image patch at spatial location $(i,j)$. 

\paragraph{(2) Pooling.} Since the coding result are highly overcomplete and highly redundant, the pooling layer aggregates the activations over certain spatial regions of the image to obtain an $M$ dimensional vector $\bx$ as the global representation of the image. Each dimension of the pooled feature $\bx_i$ is obtained by taking the activations of one code in a specific spatial region (shown as the red rectangular in Figure \ref{fig:pipeline}), and performing a predefined operator (usually average or max) on the set of activations. 

We follow a similar approach to that in \cite{Boureau:2011tz} to formally define pooled features. Specifically, given an operator $\operatorname{op}$ that maps a set of real values to a single real value (e.g.\ by taking their average), a pooled feature $x_i$ can be defined based on the selection of a code indexed by $c_i$ and a spatial region denoted by $\bR_{i}$:
\begin{equation}
  x_i = \operatorname{op} (\bA^{c_i}_{\bR_{i}})
\end{equation}
Borrowing the definition from neuroscience, we call $\bR_i$ the \emph{receptive field} for the pooled feature, which could be seen as a binary mask over the image. $\bA^{c_i}_{\bR_{i}}$ is then the set of activations of code $c_i$ in the receptive field $\bR_i$.

This definition provides a general definition that embraces existing pooling algorithms. For example, commonly used operators involve computing the statistics of the activations under the $p$-norm:
\begin{equation}
  x_i = \frac{1}{|\bR_{i}|}(\sum\nolimits_{\alpha_i \in \bA^{c_i}_{\bR_{i}}} \alpha_i^{p})^{\frac{1}{p}}
\end{equation}
when $p=1$ this corresponds to the average pooling, and when $p\rightarrow \infty$ this corresponds to the max pooling.

We focus on the definition of receptive fields for pooling. The simplest form of pooling takes the whole image as the receptive field, thus assuming a bag-of-words model where spatial information is ignored. The more commonly adopted spatial pooling approach \cite{lazebnik2006beyond,Yang:2009vb} pools features from multiple levels of regular grids, thus defining a pyramid of pooled features. Given a set of $K$ codes and a set of $N$ receptive fields, the pooled features are then defined by taking the Cartesian product of the codes and the receptive fields, yielding a $KN$-dimenisonal global feature.

Finally, a classifier, usually linear SVM or logistic regression, is trained using the global feature vector to predict the final label of the image as $y = f(\bx;\btheta)$.


\input{chap2/smartpooling}
\input{chap2/sizematters}

\section{Summary}

This chapter focused on analyzing the basic coding and pooling component of the state-of-the-art image feature extraction pipelines. Specifically, we show that smarter algorithms that explicitly take into consideration the pooling stage, whether to find better spatial receptive fields or to find pooling-aware lower level dictionaries, provide significant performance boosts in the final classification accuracies. We also reveal the underlying theoretical connection between such algorithms and \nystrom sampling, showing the possibility to transfer knowledge between these two otherwise independent research directions.

\section*{Ackowledgement}
Parts of this chapter have appeared in peer-reviewed publications as we list below:
\begin{enumerate}
\item Yangqing Jia, Chang Huang, Trevor Darrell. Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features. CVPR 2012.
\item Yangqing Jia, Oriol Vinyals, Trevor Darrell. On Compact Codes for Spatially Pooled Features. ICML 2013.
\end{enumerate}