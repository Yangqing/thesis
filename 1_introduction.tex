\chapter{Introduction}

A fundamental problem in computer vision is \emph{object recognition}: given an image composed of a grid of raw pixel values, one needs to design a computer system that identifies the objects present in this image. It is known that humans are particularly good at such problems, being able to learn quickly from very few examples (with the help of life-long visual experiences), and to adapt to various visual input conditions like illumination, rotation and deformation. By its nature, computer vision has been a vague problem, requiring one to design computer vision algorithms as well as evaluation criteria to achieve human-like vision systems.

Two key trends have driven the vision field forward during the recent years. With the highly structured visual input, it is always a challenge to find visual features that preserve useful information and provide satisfying invariance against variations. Breakthroughs in vision applications often comes with more powerful features, such as SIFT, HOG, and the recent rediscovery of convolutional neural network (CNN) features. At the same time, defining more precise problem statements as well as benchmarks almost always provides new perspectives and directions to the research field. This both helps better understanding of existing systems, and enables more powerful systems to be learned from evergrowing data.

In this thesis I present work from my PhD study that aligns with such trends: to learn a better computer vision system that learns and generalizes object categories better, and behaves in ways closer to what human learners do. As any attempt towards such a system would involve a number of key problems and challenges, I will introduce and discuss my contribution towards two problems in such vision systems: to learn better image features with solid theoretical justifications, and to re-visit the existing object recognition problem statement, proposing a novel, cognitive science inspired system that learns and generalizes object categories similar to human learners. 

It is noteworthy that vision algorithms often calls for efforts from the computer systems side, which enables one to learn from large-scale data and to learn complicated models. Such need is highlighted in the recent comeback of ``deep learning'', which employs the conventional wisdom of multi-layer, convolutional neural networks, but is usually trained with terabytes of data and millions of parameters. It is arguable that this could not be achieved by novel computer architectures - distributed systems employing thousands of machines, and heterogeneous computing platforms such as Graphical Processing Units (GPUs). However, little systematic efforts have been made to provide a state-of-the-art codebase for the recent advances in vision and deep learning. In this thesis, I will also propose and provide an open-source library called ``Caffe'' for such needs, highlighting key design choices that make it efficient. By the time of this thesis, Caffe has gained much interest both in academia and industry, and has been supporting multiple research projects both inside and outside Berkeley.

Due to the scale of topics involved in this thesis, I will leave the background and literature reviews to each individual chapter, which will be a self-containing part with discussion on how it fits in the overall theme of this thesis. Here I briefly summarize the main contribution of this thesis:
\begin{itemize}
    \item To better understand the nature of image feature learning by presenting both theoretical and empirical analysis towards more compact and effective image features, showing improvement on state-of-the-art image classification tasks (Chapter 2 and 3).
    \item To connect the gap between ``laboratory style'' object categorization and concept learning problems that are closer to human cognitive behavior, pushing the frontier on both machine vision and cognitive science (Chapter 4 and 5).
    \item To present a well-engineered, most-efficient open-source framework that fosters future computer vision and machine learning research, with systematic analyses of state-of-the-art deep learning approaches (Chapter 6).
\end{itemize}

As such, the remainder of this thesis is organized as follows:

{\bfseries Chapter 2} focuses on finding better image feature representations, which is the fundamental part of all recognition tasks. Specifically, we focus on the building block of state-of-the-art feature learning pipelines: a two-stage pipeline containing a local encoding stage and a spatial pooling stage. We show that an overcomplete pooling receptive field desing, combined with a discriminative feature selection scheme, is able to capture richer between-class variances and achieve state-of-the-art performance on benchmark datasets. While this chapter only focuses on networks with only a single coding and pooling stage, the algorithm may be extended to deeper, multi-stage networks, where one may construct a criterion for feature selection by examining the gradients of upstream networks.

{\bfseries Chapter 3} then gives a theoretical justification of overcomplete features and greedy feature selection. One could view the feature selection as a sampling problem from a potentially infinite-dimensional feature space, whose behavior could be well understood by the covariance matrix between features. While the \nystrom sampling theory has been well studied from a purely machine learning perspective, not much use has been proposed beyond simple methods such as Kmeans and SVMs. This chapter will show a natural connection between feature selection and \nystrom sampling, justifying the use of simple, greedy feature selection schemes discussed earlier in the chapter.

Having discussed the feature learning algorithms, {\bfseries Chapter 4} moves on to a higher level and analyzes the question of visual concept learning, originating from psychology and cognitive science. Specifically, we address the gap between the behavior of human and that of machines on learning a novel category by combining knowledge from two distinctive fields - machine vision and cognitive science - that have developed separately in the previous decades. As the scale of our problem has never been tried in either fields, I will propose and collect a systematic testing scheme, and present the first system that is capable of learning novel concepts directly from perceptual inputs, in a much larger scale than existing cognitive science approaches usually address.

{\bfseries Chapter 5} employs the visual concept learning framework, and presents the solution to a more conventional machine vision problem: to enable an agent that is able to learn from a large number of object categories, but is also capable of adapting to different task scenarios, and only predicting object categories that are semantically related to the current task context. The chapter benefits from the cognitive science model presented in Chapter 3, and to the best of my knowledge is the first machine vision system that addresses the semantic difference during training and testing time.

Last but not least, I present {\bfseries Chapter 6} in a more exploratory fashion than previous chapters, by evidencing and analyzing the emergence of object-level information along the multiple stages of a very deep convolutional neural network, as well as the applicability of deep features as a general-purpose feature that effectively replaces SIFT and HOG in state-of-the-art vision tasks, based on the Caffe framework that I developed and released. Chapter 6 also discusses key design choices of Caffe that plays as the backbone of all algorithms presented in the chapter.

%I will finish the thesis with a summary of contributions and several conclusional remarks presented in {\bfseries Chapter 7}, discussing possible research directions enabled by the research in this thesis. While such directions may be largely speculative, I hope it gives some insights on what future vision and cognitive science studies should be, and look forward to the realization of both more accurate and more human-like machine vision systems in the future.

